---
title: "Predicting Salary from Demographics and Professional Experience"
subtitle: "Andrew, Taran, Ashley, and Krupa"
format: 
    pdf:
        echo: false
bibliography: FinalProjectReferences.bib
editor: visual
---

# Abstract

Salaries vary greatly across countries due to multiple factors, but the key factors that influence salaries are unclear. In this project, we aim to investigate predictors of salary, including education, experience, industry, gender, and race. Using over 28,000 survey responses from AskAManager.org and data cleaning, we focused on analyzing the US, UK, and Canada for our research question: What are the key factors that influence salaries within each country, and how do these factors differ across countries? We then applied a Random Forest Classifier model to look at salary factors and to evaluate which feature was the most important. Our results showed that industry, education level, and gender are the biggest predictors of salaries. Through our exploratory data analysis, we also saw that years of experience correlates with salary. Our project suggests that education and industry matter most and don't matter with countries when determining salary levels.

# Introduction

Understanding key factors for high salaries is important for economic opportunities and not many studies focus on many factors; they often only focus on a single factor like gender or education. Research such as Blau and Kahn's Gender Wage Gap (@Blau2017) highlights this, but there is a gap in knowledge when it comes to multiple factors. Through this project, we aim to observe the importance of different factors and how they affect salaries. For example, is education or experience more important for a higher paying job? Salaries differ across countries, and we can explore these changes based on different factors.

We used survey data from @AskAManager2023, which had over 28,000 responses globally. We narrowed our focus to the US, UK, and Canada, as they dominated the number of responses in the survey (around 26,000). This dataset gave us a good opportunity to look at different demographics and professions, and also to compare between countries. Additionally, it was a great dataset to practice real-world data cleaning as it was quite messy. Our approach for data cleaning focused on normalizing currencies, experience binning, and handling missing or extra values. In our exploratory data analysis, we visualized salary distributions across key variables. Ultimately, we chose to use a Random Forest classifier because it handles mixed data well, can capture non-linear patterns and interactions between variables, which can give us feature importance, helping us identify which variables most impact salary across countries (@Breiman2001).

Our research provided us with new insights: being in the tech industry, having a master's degree and being a woman are the most important salary predictors according to our model. Surprisingly, the location doesn't seem to have a big impact on the predictions of salaries. Data analysis revealed different results: the most influential factors were having a PhD, 20-30 years of experience, being male, and being in the tech industry.

# Methods

Our project's data comes from an online Google Forms survey that was open worldwide on AskAManager.org's website. The dataset has 17 variables; the quantitative variables were the base salary, bonus income, and years of experience. The categorical variables were country, industry, education level, gender, and race. Six of the columns are free-response entries that were an addition to the main required questions, which we removed during our data cleaning. The dataset contains more than 27,000 individual data points. Around 26,000 data points were focused on the US, UK, and Canada. The project workflow is highlighted in Figure 1, where we started with data cleaning, moved onto feature engineering, data analysis, model training and then evaluating the models performance and whether it alines with any observations made during data analysis. ![Figure 1](/finalProjectFiles/projectFlow.png){width=70% fig-align="center"} 
\begin{center}
[Figure 1, Project Workflow Diagram]
\end{center}

# Data Cleaning

Surveys are a great method of data collection however they often suffer from issues due to free response answers and incomplete answers. These unconstrained answers and null values complicate our ability to use this data to make predictions or identify patterns in the data and thus a level of data cleaning is required before performing any further analysis on this data.

Our first steps were to ensure consistency throughout the data where we performed several preprocessing steps aimed at ensuring standardization of values to prepare for data analysis. This started with consolidating compensation data into a single value where we combined bonuses and base pay all into one new column named total compensation as can be seen below in Figure 2. We first check for null values as well as ensuring type safety to ensure the safe addition of the two columns. We then performe the addition and check if it was performed by printing the first few values of the dataset. Additionally, as compensation was reported in each respondents corresponding national currency, we created a new column which was the respondents total compensation normalized into USD using current exchange rates.

```{python}
import pandas as pd

# read csv file
df = pd.read_csv('salarySurveyRenamed.csv')
print("=" * 50)
# check for nulls and fill if needed
print("NaNs in salary: ", df["annualSalary"].isna().sum())
print("NaNs in Additional Income: ",df["addIncome"].isna().sum())

# fill the NaNs in additional income with 0 so I can correctly calculate total compensation
df["addIncome"] = df["addIncome"].fillna(0)
print(df["addIncome"].head(5))

# check types
df.dtypes[["annualSalary", "addIncome"]]

# convert annualSalary to type float and remove commas
df["annualSalary"] = pd.to_numeric(df["annualSalary"].astype(str).str.replace(",", ""), errors="coerce")
print(df["annualSalary"].head(5))

# now calculate for total income
df["totalCompensation"] = df["annualSalary"] + df["addIncome"]
print(df["totalCompensation"].head(5))


# we have to standardize all values to USD
# combine currency and otherCurrency
df["currency"] = df["currency"].fillna(df["otherCurrency"])

# drop otherCurrency
df = df.drop(columns=["otherCurrency"])

# find unique currencies to create dictionary for conversion
df["currency"] = df["currency"].str.strip().str.upper()
unique_currencies = df["currency"].dropna().unique()
print("=" * 50)
```

\begin{center}
[Figure 2, Total Compensation Creation from Salary and Bonus]
\end{center}

Next, we decided to remove extraneous columns and data automatically provided by google surveys that didn't match the context of our analysis or provided hard to classify data. This culminated in the removal of the timestamp column, job context and job title columns. The timestamp column just provided the time the form was submitted which provided little to no discernable data in regards to the person submitting. The job context and the job title columns did provide useful information, however, the responses in these columns were often incredibly verbose and provided far too much detail in regards to the respondents job description to the point it was far easier to group professions based on the industry column rather than attempting to bucket job titles or job context responses into a feasible number of classifications.

Because our dataset contained so many values, I decided it was best to just drop data points that were missing data in crucial categories such as gender, race, education level and industry. These categories were important for our analysis on demographic and occupational breakdowns. We considered using data augmentation techniques as an alternative to just dropping values however these attributes followed no structured pattern that would have allowed for common augmentation techniques. Given the size of the dataset, removing this sample of data still left with a large and robust sample that would still represent the population, allowing us to preserve data integrity.

In addition to incomplete entries, we also standardized key demographic columns like gender and race. Since the survey allowed for free-form text based responses, many respondents answered "man", "male", "woman" or "female" among many other responses. We decided to group these into 4 different categories just based on attempting to keep each category as balanced as possible, these categories were Man, Woman, Non-Binary and Other. Similarly, for race, we decided to group responses into broader racial groups such as Hispanic, White, Asian, Black or African American, or Other. This allowed us to retain a level of demographic specificity while ensuring that the category had a consistent set of values.

After ensuring that we dropped incomplete entries and ensuring that our key categories had consistent data, the next step was to address sections with poorly written or dirty data. Since the majority of respondents in our dataset came from the United States, United Kingdom and Canada, we decided to focus our research on these three countries for a more accurate and meaningful comparison. To support this comparison, we had to standardize country names as respondents often entered country names in inconsistent formats such as US, USA or America to indicate the United States. It was important to normalize the country data to consistent values to ensure accurate grouping and filtering later on in analysis. We created a mapping of common variations as well as common misspellings of the United States into "USA", United Kingdom into "UK" and Canada into "CANADA".

To complete the data cleaning process, we cleaned up the formatting of experience levels entries in the data. These entries had inconsistent formatting such as "2 - 4 years", "2-4years", and "1 year or less". We standardized the way experience levels into a numerical form where it was represented as two numbers separated by a hyphen such as "2-4" to represent "2-4 years" of experience. This binning of experience values made it far easier for grouping functions later on in analysis as well as having it in numerical format allowed for further feature engineering stages that may leverage these values. With this final transformation done to the data, we performed a verification of the data, checking null values, confirming data types and doing a final check that our transformations occurred, ensuring that the data was ready for statistical analysis and modeling.

# Data Analysis

Exploratory data analysis was used to visualize the distribution and impact of features. This included plots for the overall country data distribution, salary distributions within each country, and factors that influenced salary distributions within and across countries. A standard color encoding was used for the visualizations performed for each country: Green, Purple, and Orange for USA, CANADA, and UK respectively. Tools such as matplotlib, seaborn, and pandas were used for our visualizations.

**Country-Level Distributions:**\
Plotted the amount of data available for each country to understand bias, imbalance in data, and to inform our model training process later on. With a majority of data available only in the U.S., Canada, and UK, we proceeded with our analyses on these three countries. Boxplots of annual income were plotted to understand salary distributions in each country.

**Within-Country Comparisons:**\
We used boxplots to evaluate how salary is influenced by: Education Level, Years of Experience, Industry, Gender, and Race. For U.S. respondents, we further explored state-level salary differences, identifying the top and bottom five states by median salary. The top five and bottom five states based on median salaries were analyzed to examine the differences within the United States.

```{python}
#| echo: false
#imports
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import seaborn as sns
import pandas as pd
import numpy as np

#calculating z scores
df = pd.read_csv("cleandata.csv")

#creating z-score column for salaries using groupby functions 
df['z_salary_country'] = df.groupby('workCountry')['annualSalary'].transform(lambda x: (x - x.mean()) / x.std())
sns.set(style="whitegrid")

#creating mappings for each feature to create a compact graph
edu_map = {
    "Master's degree": "Grad",
    "Professional degree (MD, JD, etc.)": "Grad",
    "Bachelor's degree": "Undergrad",
    "BA/BS": "Undergraduate",
    "College degree": "Undergrad",
    "Some college": "Some Col.",
    "High School": "HS",
    "PhD": "PhD"
}

exp_map = {
    '0-1': 0.5, '2-4': 3, '5-7': 6, '8-10': 9,
    '11-20': 15.5, '21-30': 25.5, '30+': 35
}

gender_map = {
    "Woman": "Woman", "Man": "Man", "Non-binary": "Nonbinary",
    "Other or prefer not to answer": "Other",
    "Prefer not to answer": "Other"
}

race_keywords = {
    "white": "White",
    "asian or asian american": "Asian",
    "another option not listed here or prefer not to answer": "Other",
    "hispanic": "Latino",
    "latino": "Latino",
    "spanish origin": "Latino",
    "black or african american": "Black"
}
industry_map = {
    "Computing or Tech": "Tech",
    "Nonprofits": "Nonprofit",
    "Education (Higher Education)": "Higher-Ed",
    "Health care": "Health",
    "Government and Public Administration": "Govt"
}

#helper function to apply mappings for race, since this mappping is more complicated 
def map_race_label(race):
    if pd.isnull(race):
        return "Other/NA"
    race = race.lower()
    for keyword, label in race_keywords.items():
        if keyword in race:
            return label
    return "Other/NA"

#apply mapping
df['eduLevelShort'] = df['eduLevel'].map(edu_map).fillna(df['eduLevel'])
df['overallExpYears'] = df['overallProExp'].map(exp_map)
df['industryShort'] = df['industry'].map(industry_map).fillna(df['industry'])
df['genderShort'] = df['gender'].map(gender_map).fillna(df['gender'])
df['raceShort'] = df['race'].apply(map_race_label)
df['raceLabel'] = df['raceShort']  


#choose 99th percentile of salary to prevent outliers from skewing data 
salary_cap = df['annualSalary'].quantile(0.99)
df_clip = df[df['annualSalary'] < salary_cap].copy()

#select top 5 industries
top_industries = df_clip['industryShort'].value_counts().head(5).index

#select top 5 races
top_races = df_clip['raceShort'].value_counts().head(5).index

# orders for consistent graphing
edu_order = ["HS", "Some Col.", "Undergrad", "Grad", "PhD"]
gender_order = ["Woman", "Man", "Nonbinary", "Other"]
race_order = ["White", "Asian", "Latino", "Black", "Other"]
industry_order = ["Tech", "Nonprofit", "Higher-Ed", "Health", "Govt"]

fig, axes = plt.subplots(3, 5, figsize=(20, 18))  # 3 countries × (up to 5 plots each)
colors = plt.cm.Accent.colors
color_map = {'USA': colors[0], 'CANADA': colors[1], 'UK': colors[2]}
countries = ['USA', 'CANADA', 'UK']

TITLE_FONT = 16
LABEL_FONT = 15
TICK_FONT = 15

plots = [
    ("eduLevelShort", "By Education", edu_order),
    ("exp_bin", "By Experience", None),
    ("industryShort", "By Industry (Top 5)", industry_order),
    ("genderShort", "By Gender", gender_order),
    ("raceLabel", "By Race (Top 5)", race_order)
]

for row, country in enumerate(countries):
    df_country = df_clip[df_clip['workCountry'] == country].copy()
    df_country['exp_bin'] = pd.cut(df_country['overallExpYears'], bins=[0, 5, 10, 15, 20, 30, 50])
    df_industry = df_country[df_country['industryShort'].isin(top_industries)]
    df_race = df_country[df_country['raceShort'].isin(top_races)]

    data_sources = {
        "eduLevelShort": df_country,
        "exp_bin": df_country,
        "industryShort": df_industry,
        "genderShort": df_country,
        "raceLabel": df_race
    }

    for col in range(5):  # Only use first 5 plots per country (or modify if you want 5 each)
        x_var, title, order = plots[col]
        ax = axes[row, col]
        data = data_sources[x_var]

        sns.boxplot(data=data, x=x_var, y='annualSalary',
                    color=color_map[country], ax=ax, order=order)

        ax.set_title(f"{country} - {title}", fontsize=TITLE_FONT, fontweight='bold')
        ax.set_xlabel(x_var, fontsize=LABEL_FONT)
        ax.set_ylabel("Annual Salary", fontsize=LABEL_FONT)
        ax.tick_params(axis='x', labelsize=TICK_FONT, rotation=90)
        ax.tick_params(axis='y', labelsize=TICK_FONT)

# Layout fix
plt.tight_layout()

# Bounding box coordinates (after layout)
bbox = axes[0, 0].get_position()
xmin, ymin = bbox.x0, bbox.y0
xmax, ymax = bbox.x1, bbox.y1

for i in range(3):
    for j in range(5):
        box = axes[i, j].get_position()
        xmin = min(xmin, box.x0)
        ymin = min(ymin, box.y0)
        xmax = max(xmax, box.x1)
        ymax = max(ymax, box.y1)

# Draw the bounding box
rect = patches.Rectangle(
    (xmin, ymin), xmax - xmin, ymax - ymin,
    linewidth=3, edgecolor='black', facecolor='none',
    transform=fig.transFigure
)
fig.patches.append(rect)

plt.show()
```

\begin{center}
[Figure 3, Within Country Comparisons of how Salary is Influenced by 5 Features]
\end{center}

**Cross-country comparisons:**\
Boxplots were also used for comparison of how different features influence salary distributions across countries. To make salaries comparable across different economic systems, we used z-score salary distributions for each key factor above. Plots were grouped by education, experiences, gender, race, and industry to highlight how each factor affects salary relatively in each country.

```{python}
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.patches as patches

fig, axes = plt.subplots(2, 3, figsize=(20, 12))  # 2 rows x 3 columns

# Flatten axes array for easier indexing
axes = axes.flatten()

# set up color palette for consistent coloring
colors = plt.cm.Accent.colors
palette = {'USA': colors[0], 'CANADA': colors[1], 'UK': colors[2]}


# convert experience values into numeric and bin
df_clip['overallExpYears'] = df_clip['overallProExp'].map(exp_map)
df_clip['exp_bin'] = pd.cut(
    df_clip['overallExpYears'],
    bins=[0, 5, 10, 15, 20, 30, 50],
    labels=['0–5', '6–10', '11–15', '16–20', '21–30', '30+']
)


order = ['USA', 'CANADA', 'UK']  # used in hue_order

# --- 1. Education ---
sns.boxplot(data=df_clip, x='eduLevelShort', y='z_salary_country',
            hue='workCountry', hue_order=order, palette=palette,
            order=edu_order, ax=axes[0])
axes[0].axhline(0, linestyle='--', color='gray')
axes[0].set_title("Z-Score Salary by Education Level")
axes[0].tick_params(axis='x', rotation=45)

# --- 2. Experience ---
sns.boxplot(data=df_clip, x='exp_bin', y='z_salary_country',
            hue='workCountry', hue_order=order, palette=palette, ax=axes[1])
axes[1].axhline(0, linestyle='--', color='gray')
axes[1].set_title("Z-Score Salary by Experience")

# --- 3. Industry ---
df_ind = df_clip[df_clip['industryShort'].isin(top_industries)]
sns.boxplot(data=df_ind, x='industryShort', y='z_salary_country',
            hue='workCountry', hue_order=order, palette=palette,
            order=industry_order, ax=axes[2])
axes[2].axhline(0, linestyle='--', color='gray')
axes[2].set_title("Z-Score Salary by Industry (Top 5)")
axes[2].tick_params(axis='x', rotation=45)

# --- 4. Gender ---
sns.boxplot(data=df_clip, x='genderShort', y='z_salary_country',
            hue='workCountry', hue_order=order, palette=palette,
            order=gender_order, ax=axes[3])
axes[3].axhline(0, linestyle='--', color='gray')
axes[3].set_title("Z-Score Salary by Gender")

# --- 5. Race ---
df_race = df_clip[df_clip['raceShort'].isin(top_races)]
sns.boxplot(data=df_race, x='raceShort', y='z_salary_country',
            hue='workCountry', hue_order=order, palette=palette,
            order=race_order, ax=axes[4])
axes[4].axhline(0, linestyle='--', color='gray')
axes[4].set_title("Z-Score Salary by Race (Top 5)")
axes[4].tick_params(axis='x', rotation=45)

# --- 6. Empty panel ---
axes[5].axis('off')  # Hide the unused 6th subplot

# Adjust layout first
plt.tight_layout()

# Now get bounding box coordinates AFTER layout is finalized
bbox = axes[0].get_position()
xmin, ymin = bbox.x0, bbox.y0
xmax, ymax = bbox.x1, bbox.y1

for i in range(1, 5):  # Only first 5 axes
    bbox = axes[i].get_position()
    xmin = min(xmin, bbox.x0)
    ymin = min(ymin, bbox.y0)
    xmax = max(xmax, bbox.x1)
    ymax = max(ymax, bbox.y1)

# Draw the bounding rectangle with updated layout coordinates
rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,
                         transform=fig.transFigure,
                         linewidth=2, edgecolor='black', facecolor='none')
fig.patches.append(rect)

# Show the plot
plt.show()
```

\begin{center}
[Figure 4, Cross Country Comparisons of Z-Score Salary Distributions]
\end{center}

# Model Description

We employed a Random Forest Classifier to make predictions on the estimated salary brackets and bucket the results. We chose this model because it accommodates heterogeneous features– continuous variables, like total compensation (salary and bonuses combined) and years of experience, working alongside one-hot encoded features, like country, industry, and race– without requiring strict distributional assumptions or extensive feature scaling. Its robustness to outliers, inclination to capture nonlinear interactions and built-in estimation for variable importance align with our project statement and help us produce accurate predictions for salaries and rank the relative influence of socioeconomic and demographic variables.

To quantify the relative influence of different demographic and professional features on compensation, we used a multi-class salary bracket classification. totalComp was bucketed, following the US federal tax bands by applying fixed monetary cutpoints. After categorization, we were left with approximately 25900 records spanning the three major countries. All predictors, except totalComp, were retained. Numerical features were unchanged but categorical features like country, industry, etc were converted to binary indicators using one-hot encoding, with the first level dropped to avoid collinearity. In Figure 5 below, we notice the bins created for the random forest classifier to predict peoples salarys into based on the features provided in the dataset. These bins were defined by tax brackets as to be more applicable to the real world.

```{python}
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

df = pd.read_csv('cleandata.csv')

# Define bins and labels with ranges attached
bins = [0, 11000, 44725, 95375, 182100, 231250, float('inf')]
labels = [
    'Low (0–11k)',
    'Lower Middle (11k–44.7k)',
    'Middle (44.7k–95.3k)',
    'Upper Middle (95.3k–182.1k)',
    'High (182.1k–231.2k)',
    'Very High (231.2k+)'
]

# Apply the cut
df['SalaryCategory'] = pd.cut(df['compUSD'], bins=bins, labels=labels)
print("=" * 50)
# View counts per category
print(df['SalaryCategory'].value_counts())
print(df[['compUSD', 'SalaryCategory']].head())
print("=" * 50)
```

\begin{center}
[Figure 5, Salary Bins for RandomForest Classifier]
\end{center}

The data was partitioned into a 80/20 training-testing split. We fitted the RandomForestClassifier from the scikit-learn library with n_estimators=16 and random_state= 42(default depth and split criteria). The forest, despite having a relatively small size, was able to converge while keeping inference latency to a minimum. No additional hyperparameter tuning was applied because the grid search did not improve validation accuracy, but that is an avenue that could be explored in the future. Model assessment used accuracy and the macro‑averaged precision, recall and F‑score as supplied by the classification_report utility.

# Results

**Key Insights from EDA**\
From our EDA, several clear patterns emerged. The technology industry, 20–30 years of experience, and holding a PhD were consistently associated with higher median salaries across all three countries. However, the strength of these effects varied by country. The impact of working in tech and having a PhD was more pronounced in the US, while in the UK, years of experience (particularly 21–30 years) had a stronger influence on salary. Significant gender disparities were also observed. In all three countries, women and nonbinary individuals had lower median salaries compared to men, with the gap being most prominent in the US (as shown in Figure 3).

Race also showed a notable effect: identifying as Asian was associated with higher median earnings in both the US and UK, with a stronger impact in the US. Therefore, higher salaries were more likely among Asian individuals, especially in the US context. These insights informed our modeling approach by highlighting the most predictive features for salary and emphasizing where country-specific adjustments might be necessary.

**Random Forest Results**\
The forest achieved an overall accuracy of 0.88 on the test set and a weighted F-score of 0.86. Performance was heterogeneous across all salary bands: majority data was collected from the middle class, which led to the model classifying that part of the data almost perfectly, but the minority low class was rarely recovered, leading to negligible precision and recall. Despite this problem, the model's macro average F-score is acceptable for descriptive purposes proving that our chosen feature set contains more than enough signal to categorize the broad compensation distribution. We can see a more in-depth classification report below in Figure 6 as produced by sklearn metrics.

```{python}
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

df = pd.read_csv('cleandata.csv')

# Define bins and labels with ranges attached
bins = [0, 11000, 44725, 95375, 182100, 231250, float('inf')]
labels = [
    'Low (0–11k)',
    'Lower Middle (11k–44.7k)',
    'Middle (44.7k–95.3k)',
    'Upper Middle (95.3k–182.1k)',
    'High (182.1k–231.2k)',
    'Very High (231.2k+)'
]

# Apply the cut
df['SalaryCategory'] = pd.cut(df['compUSD'], bins=bins, labels=labels)


# Drop rows where salary category couldn't be assigned (NaN)
df = df.dropna(subset=['SalaryCategory'])


# drop all columns associated with salary and compensation
df.drop(columns=['annualSalary', 'addIncome'], inplace=True)

# Features and target
X = df.drop(columns=['compUSD', 'SalaryCategory'])
y = df['SalaryCategory']

# Convert categorical features to numeric
X = pd.get_dummies(X, drop_first=True)

# Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=df['workCountry'])


clf = RandomForestClassifier(
    n_estimators=120,
    random_state=42,
    max_depth=100,
)
clf.fit(X_train, y_train)

# Predict and evaluate
y_pred = clf.predict(X_test)
print("=" * 50)
print(classification_report(y_test, y_pred))
print("[Figure 6, Random Forest Prediction Results]")
print("=" * 50)

# Get feature importances
importances = clf.feature_importances_

# Get feature names
feature_names = X_train.columns

# Create a DataFrame for better visualization
feature_importances = pd.DataFrame({'feature': feature_names, 'importance': importances})

# Sort the DataFrame by importance
feature_importances = feature_importances.sort_values(by='importance', ascending=False)

top_n = 15  # Change to however many top features you want to display
top_features = feature_importances.iloc[1:top_n]

plt.figure(figsize=(10, 6))
plt.barh(top_features['feature'][::-1], top_features['importance'][::-1])  # Reverse for highest on top
plt.xlabel('Importance')
plt.title(f'Top {top_n} Feature Importances')
plt.tight_layout()
plt.show()
```

\begin{center}
[Figure 7, Most Important Features on Classification as indicated by Tree]
\end{center}

The presentation finding that industry membership (particularly in the technology sector), postgraduate education, and self-identified gender exert the largest marginal effects on the predicted bracket, while the country indicator contributes relatively little once all salaries are expressed in U.S. dollars, was replicated by qualitative inspection of impurity-based feature importances. These patterns are mostly consistent with the patterns observed in the exploratory data analysis section.

In summary, the random forest classifier model was able to capture the dominant trends in the cleaned dataset and its feature importance scores clearly demonstrates the important variables, preserving interpretability and giving us reliable predictions.

# Discussion

Our model results and data analysis reinforce the idea that industry and education level are the most important influences on higher salaries. Gender differences in salary also were significant, which exhibits the everlasting gender wage gap. Interestingly, the impact of location was minimal in our model once industry and education were accounted for. This suggests that global shifts in remote work and skill-based pay are changing salary structures!

However, there are certain limitations to our research. Because the data survey was self-reported, there may be bias in salary information or demographic accuracy. Additionally, the overwhelming number of responses from the US limits how much we can generalize our findings to other parts of the world. Nevertheless, the consistency of our evaluation across the three countries we analyzed shows that it may be okay to generalize these results because they are similar across the US, UK, and Canada.

Nevertheless, the consistency of model rankings across the three countries we analysed suggests our central message is robust. Industry and education dominate, gender differentials persist, and geography matters lesser and lesser once pay is converted to a common currency. Future work could (i) supplement self‑reports with verified compensation databases, (ii) oversample regions outside North America and the UK, (iii) incorporate cost‑of‑living or purchasing‑power adjustments, and (iv) apply explainable‑AI tools such as SHAP values to probe whether feature effects vary within remote‑only subsamples. Such extensions would sharpen our understanding of how the evolving mix of remote work, skills‑based hiring, and demographic factors is reshaping the global salary landscape.

# Conclusion

Our project highlights that industry, education, and gender are the major factors influencing salary. Contrary to our expectations and our initial breakdown of our work, the country of employment had a small effect. Increasing experience does boost salary, but its effect is not as large after the threshold of 20 years is hit. For the future, we can expand our analysis to more countries and industries to improve global representation; additionally, we can also adjust for cost-of-living and job markets for our analysis and model.

# Roles

Andrew was responsible for data cleaning and performed all of the data cleaning tasks. Krupa performed some feature engineering and split up the exploratory data analysis with Ashley and looked into the salary distributions in detail. Taran and Andrew worked on the model together. All members of the team worked together for the final presentation and final report.

# References